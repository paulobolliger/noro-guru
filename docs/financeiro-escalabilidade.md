# ğŸ—ï¸ EstratÃ©gia de Escalabilidade - MÃ³dulo Financeiro NORO

## ğŸ“‹ DecisÃ£o Arquitetural: **Mesmo BD (por enquanto)**

### âœ… Justificativa
- Volume inicial serÃ¡ baixo (< 100k transaÃ§Ãµes/mÃªs)
- RLS do Supabase jÃ¡ separa dados por tenant
- Simplicidade operacional e de desenvolvimento
- Custo otimizado

---

## ğŸ“Š Estimativa de Volume por Fase

### **Fase 1: MVP (0-6 meses)**
- **Tenants ativos**: 5-10
- **TransaÃ§Ãµes/mÃªs**: ~10k-50k
- **Tamanho BD**: ~500MB
- **ConexÃµes simultÃ¢neas**: < 20
- **Status**: âœ… MESMO BD - Sem problemas

### **Fase 2: Crescimento (6-18 meses)**
- **Tenants ativos**: 50-100
- **TransaÃ§Ãµes/mÃªs**: ~200k-500k
- **Tamanho BD**: ~5-10GB
- **ConexÃµes simultÃ¢neas**: 30-50
- **Status**: âš ï¸ MONITORAR - Ãndices compostos crÃ­ticos

### **Fase 3: Escala (18+ meses)**
- **Tenants ativos**: 100+
- **TransaÃ§Ãµes/mÃªs**: > 1M
- **Tamanho BD**: > 50GB
- **ConexÃµes simultÃ¢neas**: > 60
- **Status**: ğŸš¨ SEPARAR BD ou PARTICIONAR

---

## ğŸ¯ MÃ©tricas de Monitoramento

### ğŸŸ¢ **Indicadores SaudÃ¡veis (Ficar no mesmo BD)**
```sql
-- LatÃªncia de queries < 200ms
EXPLAIN ANALYZE 
SELECT * FROM fin_receitas 
WHERE tenant_id = 'xxx' AND status = 'pendente';

-- Ãndice hit rate > 99%
SELECT 
  schemaname,
  tablename,
  idx_scan,
  idx_tup_read,
  idx_tup_fetch
FROM pg_stat_user_indexes
WHERE schemaname = 'public' AND tablename LIKE 'fin_%';

-- Tamanho total das tabelas financeiras
SELECT 
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public' AND tablename LIKE 'fin_%'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

### ğŸ”´ **Alertas CrÃ­ticos (Hora de separar)**
- âŒ Queries financeiras > 500ms consistentemente
- âŒ Pool de conexÃµes > 80% de uso
- âŒ Lock timeouts frequentes
- âŒ Tabelas financeiras > 50GB
- âŒ Dashboard demorando > 2s para carregar

---

## ğŸ› ï¸ OtimizaÃ§Ãµes Implementadas

### âœ… **JÃ¡ Feito na Migration**
1. **Ãndices Simples**: tenant_id, marca, status, datas
2. **Ãndices Compostos**: (tenant_id, status), (tenant_id, data_competencia)
3. **Ãndices Parciais**: SÃ³ para registros pendentes/atrasados (economiza espaÃ§o)
4. **Campos Computed**: `valor_brl` calculado automaticamente (evita JOIN)
5. **Triggers Otimizados**: AtualizaÃ§Ã£o de saldo em tempo real

### ğŸš€ **PrÃ³ximas OtimizaÃ§Ãµes (Quando NecessÃ¡rio)**

#### **NÃ­vel 1: Query Optimization (Fase 2)**
```sql
-- Materialized View para Dashboard (atualizada a cada 15min)
CREATE MATERIALIZED VIEW mv_fin_dashboard_kpis AS
SELECT 
  tenant_id,
  marca,
  DATE_TRUNC('month', data_competencia) as mes,
  SUM(CASE WHEN status = 'pago' THEN valor_brl ELSE 0 END) as receita_mensal,
  COUNT(CASE WHEN recorrente = true THEN 1 END) as clientes_recorrentes
FROM fin_receitas
GROUP BY 1, 2, 3;

CREATE UNIQUE INDEX ON mv_fin_dashboard_kpis (tenant_id, marca, mes);

-- Refresh automÃ¡tico via cron job
-- pg_cron: SELECT cron.schedule('refresh-kpis', '*/15 * * * *', 
--   'REFRESH MATERIALIZED VIEW CONCURRENTLY mv_fin_dashboard_kpis');
```

#### **NÃ­vel 2: Particionamento por Data (Fase 3)**
```sql
-- Converter tabelas em particionadas (REQUER DOWNTIME)
ALTER TABLE fin_receitas RENAME TO fin_receitas_old;

CREATE TABLE fin_receitas (
  -- mesmo schema...
) PARTITION BY RANGE (data_competencia);

-- Criar partiÃ§Ãµes mensais
CREATE TABLE fin_receitas_2025_01 PARTITION OF fin_receitas
  FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE fin_receitas_2025_02 PARTITION OF fin_receitas
  FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

-- Migrar dados
INSERT INTO fin_receitas SELECT * FROM fin_receitas_old;

-- Script de manutenÃ§Ã£o: criar partiÃ§Ã£o do prÃ³ximo mÃªs
CREATE OR REPLACE FUNCTION criar_particao_mes_seguinte()
RETURNS void AS $$
DECLARE
  proximo_mes date := DATE_TRUNC('month', NOW() + INTERVAL '1 month');
  mes_seguinte date := proximo_mes + INTERVAL '1 month';
  nome_particao text := 'fin_receitas_' || TO_CHAR(proximo_mes, 'YYYY_MM');
BEGIN
  EXECUTE format(
    'CREATE TABLE IF NOT EXISTS %I PARTITION OF fin_receitas 
     FOR VALUES FROM (%L) TO (%L)',
    nome_particao, proximo_mes, mes_seguinte
  );
END;
$$ LANGUAGE plpgsql;
```

#### **NÃ­vel 3: Archiving de Dados Antigos**
```sql
-- Mover dados > 2 anos para tabela de arquivo
CREATE TABLE fin_receitas_archive (LIKE fin_receitas INCLUDING ALL);

INSERT INTO fin_receitas_archive 
SELECT * FROM fin_receitas 
WHERE data_competencia < NOW() - INTERVAL '2 years';

DELETE FROM fin_receitas 
WHERE data_competencia < NOW() - INTERVAL '2 years';
```

---

## ğŸ”„ EstratÃ©gia de MigraÃ§Ã£o para BD Separado

### **Quando decidir separar?**
Se **3 ou mais** dessas condiÃ§Ãµes forem verdadeiras:
- [ ] Volume > 1M transaÃ§Ãµes/mÃªs
- [ ] LatÃªncia > 500ms em queries financeiras
- [ ] Tabelas financeiras > 50GB
- [ ] Precisa de SLA diferente (99.99% uptime)
- [ ] RegulatÃ³rio exige isolamento fÃ­sico

### **Plano de MigraÃ§Ã£o (Zero Downtime)**

#### **Passo 1: Criar novo projeto Supabase**
```bash
# Novo projeto: noro-financeiro
SUPABASE_FINANCEIRO_URL=https://xxx.supabase.co
SUPABASE_FINANCEIRO_KEY=xxx
```

#### **Passo 2: ReplicaÃ§Ã£o Dual-Write**
```typescript
// Escrever nos 2 BDs simultaneamente (transitÃ³rio)
async function criarReceita(data: FinReceitaInsert) {
  const [resultPrincipal, resultFinanceiro] = await Promise.all([
    supabasePrincipal.from('fin_receitas').insert(data),
    supabaseFinanceiro.from('fin_receitas').insert(data)
  ]);
  
  // Validar consistÃªncia
  if (resultPrincipal.error || resultFinanceiro.error) {
    // Rollback ou retry
  }
}
```

#### **Passo 3: MigraÃ§Ã£o de Dados HistÃ³ricos**
```bash
# Dump apenas tabelas financeiras
pg_dump $SUPABASE_PRINCIPAL_URL \
  -t fin_* \
  --data-only \
  --file=financeiro_data.sql

# Restore no novo BD
psql $SUPABASE_FINANCEIRO_URL < financeiro_data.sql
```

#### **Passo 4: Cutover**
```typescript
// Feature flag para direcionar 100% para novo BD
if (FINANCEIRO_NEW_DB_ENABLED) {
  return supabaseFinanceiro.from('fin_receitas')...
} else {
  return supabasePrincipal.from('fin_receitas')...
}
```

---

## ğŸ’° AnÃ¡lise de Custo

### **CenÃ¡rio 1: Mesmo BD (Atual)**
- **Supabase Pro**: $25/mÃªs
- **Aumento de storage**: ~$0.10/GB/mÃªs
- **Custo estimado Fase 2**: $30-40/mÃªs
- **Custo estimado Fase 3**: $50-80/mÃªs

### **CenÃ¡rio 2: BD Separado**
- **Supabase Principal**: $25/mÃªs
- **Supabase Financeiro**: $25/mÃªs
- **Custo total**: $50/mÃªs + storage
- **Break-even**: SÃ³ vale a pena se performance for crÃ­tica

### **RecomendaÃ§Ã£o**: Ficar no mesmo BD atÃ© Fase 3, economizando ~$300-600/ano

---

## ğŸ¯ ConclusÃ£o e PrÃ³ximos Passos

### âœ… **DecisÃ£o Final: INICIAR NO MESMO BD**

**AÃ§Ãµes Imediatas:**
1. âœ… Rodar migration com Ã­ndices otimizados
2. â³ Configurar dashboard de monitoramento (pg_stat_statements)
3. â³ Definir alertas de performance no Supabase
4. â³ Documentar thresholds de migraÃ§Ã£o

**RevisÃ£o Futura:**
- ğŸ“… **3 meses**: Analisar volume e performance
- ğŸ“… **6 meses**: Avaliar se Ã­ndices estÃ£o sendo usados
- ğŸ“… **12 meses**: Decidir sobre particionamento
- ğŸ“… **18 meses**: Reavaliar necessidade de BD separado

---

## ğŸ“ Quando Pedir Ajuda?

Se qualquer desses cenÃ¡rios acontecer:
- ğŸš¨ Dashboard demorando > 3 segundos
- ğŸš¨ Timeouts em transaÃ§Ãµes financeiras
- ğŸš¨ RelatÃ³rios de BI travando
- ğŸš¨ Clientes reclamando de lentidÃ£o

**AÃ§Ã£o**: Contratar consultoria especializada em PostgreSQL/Supabase para otimizaÃ§Ã£o avanÃ§ada.
